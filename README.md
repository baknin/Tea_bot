# Tea_bot

1. Обзор проекта
  Данный проект реализует автономного робота, который по жесту человека определяет его местоположение за столом, подъезжает к ближайшему стакану, наливает фиксированный объём чая и возвращается на базу для дозаправки. Система построена на связке TouchDesigner (компьютерное зрение, распознавание жестов, планирование маршрута) и Raspberry Pi (управление моторами и помпой). Компоненты общаются по протоколу UDP через Wi‑Fi.
  
  Ключевые особенности:
  Распознавание жестов в реальном времени (MediaPipe + TouchDesigner).
  Определение координат человека за столом (по плечам или лицу).
  Детекция стаканов (компьютерное зрение или ArUco‑маркеры).
  Планирование маршрута до стакана и обратно на базу.
  Автоматическое выполнение команд роботом (движение, налив).

2. Принцип работы программы (пошагово)
Система работает циклически, каждый цикл состоит из следующих этапов:
Этап 1: Распознавание жеста и позиции человека
  Человек садится за стол и показывает заранее определённый жест (например, «указательный палец вверх»).
  Камера (глубинная или RGB), установленная над столом, передаёт видеопоток в TouchDesigner.
  В TouchDesigner модуль gesture_detection с помощью плагина MediaPipe отслеживает руки и классифицирует жест.
  Одновременно модуль person_localization определяет ключевые точки тела (плечи, торс) или лицо, вычисляя координаты человека в системе координат стола. Эти координаты передаются планировщику.

Этап 2: Выбор стакана
  Модуль cup_detection анализирует тот же видеопоток (или отдельный снимок) и находит все стаканы на столе, сохраняя их координаты (X, Y) в таблице.
  Планировщик (path_planner) получает координаты человека и список стаканов. Выбирается стакан, ближайший к текущей позиции человека (или стакан, закреплённый за этим человеком, если используется идентификация по лицу).

Этап 3: Планирование маршрута
  База робота имеет фиксированные координаты (0,0) или помечена ArUco‑маркером.
  Планировщик строит траекторию от базы до выбранного стакана. При отсутствии препятствий маршрут представляет собой отрезок прямой. При наличии препятствий (другие стаканы) может использоваться алгоритм поиска пути (например, A* на сетке).
  Траектория преобразуется в последовательность элементарных команд движения: ВПЕРЕД N см, ПОВОРОТ_НАЛЕВО N градусов, СТОП.

Этап 4: Отправка команд роботу
  Модуль udp_comm в TouchDesigner упаковывает команды в текстовые строки (например, MOVE:FORWARD:50) и отправляет их по UDP на IP‑адрес Raspberry Pi, установленного на роботе.
  Для повышения надёжности можно организовать подтверждение получения каждой команды (ответ от робота).
  
Этап 5: Исполнение роботом
  На Raspberry Pi работает Python‑скрипт, который слушает UDP‑порт.
  Получив команду, скрипт парсит её и через GPIO управляет моторами (драйвер двигателей) и помпой.
  После выполнения команды (например, налива) робот отправляет обратно статус STATUS:POURED.

Этап 6: Возврат на базу
  Получив подтверждение об окончании налива, планировщик строит обратный маршрут от текущего положения робота до базы.
  Команды отправляются роботу, и он возвращается на базу.
  По прибытии робот переходит в режим ожидания следующей команды. При необходимости на базе происходит долив чая в бак робота (вручную или автоматически).

3. Определение маршрута и нахождение стакана в пространстве
  Система координат стола
  За начало координат (0,0) принимается точка базы робота.
  Ось X направлена вдоль стола, ось Y – поперёк.
  Все реальные размеры переводятся в сантиметры или условные единицы (пиксели после калибровки).
  
  Детекция стаканов
  Для обнаружения стаканов используется один из методов (или их комбинация):
  Поиск кругов – функция cv2.HoughCircles в OpenCV, встроенная в TouchDesigner через Python‑скрипт.
  Цветовая сегментация – если стаканы имеют характерный цвет (например, белые), можно выделить их по цветовому диапазону.
  ArUco‑маркеры – на каждый стакан наклеивается уникальный маркер; библиотека aruco позволяет мгновенно получить ID и координаты. Этот метод наиболее надёжен.
  Результат детекции – таблица с колонками: id_стакана, x_стола, y_стола.
  
  Определение положения человека
  MediaPipe Pose – определяет ключевые точки тела. Для координат человека берётся среднее между плечевыми точками или точка центра груди.
  MediaPipe Face Detection – если важна идентификация конкретного человека, можно распознавать лицо и привязывать к нему стакан.
  Полученные в пикселях координаты переводятся в координаты стола с помощью матрицы гомографии, рассчитанной при калибровке камеры.
  
  Планирование маршрута
  В простейшем случае, когда стол пуст, маршрут – прямая линия от базы до стакана. Для этого достаточно:
  Вычислить вектор (dx, dy) от базы до стакана.
  Определить угол поворота робота: angle = atan2(dy, dx).
  Задать расстояние: dist = sqrt(dx^2 + dy^2).
  Сформировать команды: TURN:angle (если робот может поворачивать на месте) и MOVE:FORWARD:dist.
  При наличии препятствий можно реализовать алгоритм A* на дискретной сетке. В TouchDesigner это удобно сделать с помощью Script DAT, написав функцию поиска пути на Python.

4. Взаимодействие Raspberry Pi и TouchDesigner
  Протокол связи: UDP
  Порт для команд: 8888 (может быть изменён).
  Порт для статусов: 8889.
  Формат сообщений
  Используются простые текстовые строки с разделителем :.
  Команды от TouchDesigner к роботу:
  MOVE:FORWARD:<расстояние_в_см> – ехать вперёд.
  MOVE:BACKWARD:<расстояние_в_см> – ехать назад.
  TURN:LEFT:<угол_в_градусах> – повернуть налево.
  TURN:RIGHT:<угол_в_градусах> – повернуть направо.
  PUMP:ON:<время_в_мс> – включить помпу на указанное время (налив).
  STOP – экстренная остановка.
  Статусы от робота к TouchDesigner:
  STATUS:ARRIVED – робот прибыл в точку.
  STATUS:POURED – налив завершён
  STATUS:BASE – робот вернулся на базу.
  ERROR:OBSTACLE – обнаружено препятствие (опционально).
  
  Реализация в TouchDesigner
  Отправка: UDP Send DAT – в поле "destination" указывается IP Raspberry Pi и порт 8888. Строки формируются из таблицы команд.
  Приём: UDP Receive DAT – слушает порт 8889, выводит полученные сообщения в таблицу для дальнейшей обработки (логирование, обновление статуса).

6. Структура проекта в TouchDesigner
  Проект организован в виде иерархии компонентов (файлов .tox), что обеспечивает модульность и лёгкость отладки.

  Проект "Чайный Жест"/
    ├── main.toe                     # Основной файл, подгружающий все компоненты
    └── components/                   # Папка с компонентами
        ├── camera_input.tox          # Захват видео с камеры
        ├── gesture_detection.tox     # Распознавание жестов (MediaPipe)
        ├── person_localization.tox    # Определение координат человека
        ├── cup_detection.tox          # Детекция стаканов (OpenCV / ArUco)
        ├── path_planner.tox           # Планирование маршрута (выбор стакана, построение пути)
        ├── udp_comm.tox               # Отправка/приём UDP сообщений
        └── ui.tox                      # Интерфейс оператора

7. Структура проекта на Ruspberry Pi
  /home/pi/robot_cpp/
  ├── include/
  │   ├── MotorController.h
  │   ├── Pump.h
  │   ├── UDPComm.h
  │   ├── CommandQueue.h
  │   └── Config.h
  ├── src/
  │   ├── main.cpp
  │   ├── MotorController.cpp
  │   ├── Pump.cpp
  │   ├── UDPComm.cpp
  │   └── CommandQueue.cpp
  ├── CMakeLists.txt (или Makefile)
  └── config.txt (параметры: IP сервера, порты, калибровочные коэффициенты)

8. Объединение компонентов на сервере
  Сервером выступает компьютер, на котором запущен TouchDesigner. Он выполняет роль центра управления:
  Видеообработка – все алгоритмы компьютерного зрения работают внутри TouchDesigner (MediaPipe, OpenCV).
  Принятие решений – логика выбора стакана, планирование маршрута.
  Коммуникация – отправка команд роботу и приём обратной связи.
  Raspberry Pi – это лишь «тонкий клиент», который исполняет примитивные команды. Такое разделение позволяет:
  Снизить нагрузку на Raspberry Pi (он не занимается компьютерным зрением).
  Использовать мощный ПК для сложных вычислений.
  Легко отлаживать и модифицировать логику в визуальной среде TouchDesigner.
  Связка на сервере подразумевает, что все компоненты TouchDesigner взаимодействуют внутри одного процесса. Внешнее взаимодействие – только UDP с роботом. Дополнительно можно организовать веб‑интерфейс для мониторинга, но это уже расширение.

9. Калибровка и настройка
  Для корректной работы необходимо выполнить предварительную калибровку:
  Калибровка камеры: определить матрицу гомографии для преобразования пиксельных координат в реальные сантиметры на столе. Это делается с помощью размещения на столе калибровочного паттерна (например, шахматной доски) и вычисления матрицы через OpenCV.
  Настройка жестов: в компоненте gesture_detection задать пороговые значения расстояний между пальцами для каждого жеста.
  Параметры движения робота: в config.py на Raspberry Pi подобрать коэффициенты CM_PER_SECOND и угловые скорости, чтобы команды MOVE:FORWARD:10 действительно перемещали робота на 10 см.

10. Заключение и перспективы
  Разработанная архитектура обеспечивает гибкость и масштабируемость. В минимальной версии робот способен выполнять базовую задачу. В дальнейшем можно добавить:
  Распознавание нескольких людей и назначение стаканов по лицам.
  Обнаружение препятствий (датчики на роботе) и динамическое перепланирование маршрута.
  Автоматическую дозаправку чаем на базе.
  Голосовое подтверждение и синтез речи.
  Проект полностью готов к реализации и может служить отличной демонстрацией возможностей связки TouchDesigner и Raspberry Pi в робототехнике.
